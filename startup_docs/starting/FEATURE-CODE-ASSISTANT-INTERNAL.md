# ğŸ¤– AI Code Assistant - Auto-Correction Interne

## ğŸ¯ Objectif

SystÃ¨me d'assistance IA pour **corriger automatiquement les bugs** et **amÃ©liorer la qualitÃ© du code** de ton SaaS en cours de dÃ©veloppement.

**Usage** : Outil interne (pas un produit Ã  vendre)

---

## ğŸ’¡ Contexte & ProblÃ¨me RÃ©solu

### ProblÃ¨me
- ğŸ› Bugs dÃ©tectÃ©s en production nÃ©cessitent intervention manuelle
- â±ï¸ Temps perdu Ã  dÃ©bugger des erreurs simples
- ğŸ“‰ QualitÃ© du code variable selon la fatigue/pression
- ğŸ”„ Refactoring manuel long et fastidieux
- ğŸ—ï¸ Difficile de maintenir cohÃ©rence architecturale

### Solution
SystÃ¨me IA qui :
- âœ… DÃ©tecte et corrige automatiquement les bugs
- âœ… Analyse le code Ã  chaque commit
- âœ… Valide le respect de l'architecture
- âœ… SuggÃ¨re des amÃ©liorations continues
- âœ… GÃ©nÃ¨re des tests automatiquement

---

## ğŸ—ï¸ Architecture

```
app/ai/modules/code_assistant/
â”œâ”€â”€ manifest.yaml                   # Configuration du module
â”œâ”€â”€ __init__.py                     # Entry point
â”‚
â”œâ”€â”€ ğŸ“‚ core/
â”‚   â”œâ”€â”€ service.py                  # CodeAssistantService (orchestration)
â”‚   â”œâ”€â”€ context_builder.py          # Construit contexte depuis project-map.json
â”‚   â””â”€â”€ config.py                   # Configuration
â”‚
â”œâ”€â”€ ğŸ“‚ analyzers/                   # Analyseurs de code
â”‚   â”œâ”€â”€ bug_analyzer.py             # DÃ©tecte bugs potentiels
â”‚   â”œâ”€â”€ security_analyzer.py        # Scan vulnÃ©rabilitÃ©s (SQL injection, XSS, etc.)
â”‚   â”œâ”€â”€ performance_analyzer.py     # DÃ©tecte goulots d'Ã©tranglement
â”‚   â”œâ”€â”€ architecture_validator.py   # Valide respect de l'architecture
â”‚   â””â”€â”€ code_quality_analyzer.py    # Code smells, complexitÃ© cyclomatique
â”‚
â”œâ”€â”€ ğŸ“‚ fixers/                      # GÃ©nÃ©rateurs de corrections
â”‚   â”œâ”€â”€ auto_fixer.py               # GÃ©nÃ¨re corrections automatiques
â”‚   â”œâ”€â”€ pr_creator.py               # CrÃ©e PR GitHub avec le fix
â”‚   â”œâ”€â”€ test_generator.py           # GÃ©nÃ¨re tests unitaires
â”‚   â””â”€â”€ documentation_generator.py  # GÃ©nÃ¨re docstrings
â”‚
â”œâ”€â”€ ğŸ“‚ providers/                   # Providers IA
â”‚   â”œâ”€â”€ base_provider.py            # Interface abstraite
â”‚   â”œâ”€â”€ openai_provider.py          # GPT-4 (analyse profonde)
â”‚   â”œâ”€â”€ claude_provider.py          # Claude (code review)
â”‚   â””â”€â”€ local_analyzer.py           # Outils locaux (pylint, mypy, ruff)
â”‚
â”œâ”€â”€ ğŸ“‚ hooks/                       # Hooks systÃ¨me
â”‚   â”œâ”€â”€ pre_commit_hook.py          # Analyse avant commit
â”‚   â”œâ”€â”€ post_deploy_hook.py         # Validation aprÃ¨s dÃ©ploiement
â”‚   â”œâ”€â”€ exception_handler.py        # Capture erreurs production
â”‚   â””â”€â”€ ci_integration.py           # IntÃ©gration CI/CD
â”‚
â”œâ”€â”€ ğŸ“‚ models/                      # ModÃ¨les de donnÃ©es
â”‚   â”œâ”€â”€ analysis_result.py          # RÃ©sultat d'analyse
â”‚   â”œâ”€â”€ fix_suggestion.py           # Suggestion de correction
â”‚   â””â”€â”€ code_context.py             # Contexte du code
â”‚
â”œâ”€â”€ ğŸ“‚ utils/
â”‚   â”œâ”€â”€ ast_parser.py               # Parse AST Python
â”‚   â”œâ”€â”€ diff_analyzer.py            # Analyse les diffs Git
â”‚   â””â”€â”€ metrics_calculator.py      # Calcule mÃ©triques (complexitÃ©, etc.)
â”‚
â”œâ”€â”€ routes.py                       # API endpoints (usage interne)
â”œâ”€â”€ schemas.py                      # Pydantic schemas
â””â”€â”€ README.md
```

---

## ğŸ¯ Cas d'Usage DÃ©taillÃ©s

### 1. ğŸš¨ Auto-Healing System (Correction Auto en Production)

**ScÃ©nario** : Une erreur est levÃ©e en production

```python
# app/core/middleware/exception_handler.py

from app.ai.modules.code_assistant.core.service import CodeAssistantService
from app.ai.modules.code_assistant.fixers.pr_creator import PRCreator

@app.exception_handler(Exception)
async def auto_healing_handler(request: Request, exc: Exception):
    """
    Workflow:
    1. Capture l'exception complÃ¨te
    2. Extrait le contexte (fichier, ligne, traceback)
    3. Charge le contexte projet depuis project-map.json
    4. Envoie Ã  l'AI pour analyse
    5. AI gÃ©nÃ¨re un fix
    6. CrÃ©e une PR GitHub automatique
    7. Notifie le dev + log audit
    8. Retourne erreur gracieuse Ã  l'utilisateur
    """
    
    # 1. Capture contexte complet
    error_context = {
        "error_type": type(exc).__name__,
        "error_message": str(exc),
        "traceback": traceback.format_exc(),
        "file_path": exc.__traceback__.tb_frame.f_code.co_filename,
        "line_number": exc.__traceback__.tb_lineno,
        "function_name": exc.__traceback__.tb_frame.f_code.co_name,
        
        # Contexte requÃªte
        "request_url": str(request.url),
        "request_method": request.method,
        "user_id": getattr(request.state, "user_id", None),
        
        # Contexte systÃ¨me
        "timestamp": datetime.utcnow().isoformat(),
        "environment": settings.ENVIRONMENT,
        
        # Variables locales au moment de l'erreur
        "local_vars": exc.__traceback__.tb_frame.f_locals
    }
    
    # 2. Charge contexte projet
    code_assistant = CodeAssistantService()
    project_context = code_assistant.load_project_context(
        file_path=error_context["file_path"]
    )
    
    # 3. Analyse avec AI
    analysis = await code_assistant.analyze_error(
        error_context=error_context,
        project_context=project_context
    )
    
    # 4. GÃ©nÃ¨re un fix si l'AI est confiant
    if analysis.confidence > 0.85 and analysis.fix_available:
        fix = await code_assistant.generate_fix(analysis)
        
        # 5. CrÃ©e une PR GitHub
        pr_creator = PRCreator()
        pr_url = await pr_creator.create_fix_pr(
            branch_name=f"auto-fix/{{error_context['error_type']}}-{{datetime.utcnow().timestamp()}}",
            fix=fix,
            error_context=error_context,
            analysis=analysis
        )
        
        # 6. Notification
        await notify_dev(
            title=f"ğŸ¤– Auto-Fix crÃ©Ã©: {{error_context['error_type']}}",
            message=f"PR crÃ©Ã©e automatiquement: {{pr_url}}",
            priority="medium"
        )
        
        # 7. Log audit
        await audit_log.log_auto_fix(
            error=error_context,
            analysis=analysis,
            fix=fix,
            pr_url=pr_url
        )
    else:
        # Pas assez confiant, crÃ©e juste une issue GitHub
        await github_service.create_bug_issue(
            title=f"ğŸ› {{error_context['error_type']}}: {{error_context['error_message'][:50]}}",
            body=format_issue_body(error_context, analysis)
        )
    
    # 8. Retourne erreur gracieuse
    return JSONResponse(
        status_code=500,
        content={
            "error": "Une erreur est survenue",
            "message": "Notre Ã©quipe a Ã©tÃ© notifiÃ©e et travaille sur une correction",
            "reference_id": error_context["timestamp"]
        }
    )
```

**RÃ©sultat** :
- âœ… Bug dÃ©tectÃ© automatiquement
- âœ… Fix gÃ©nÃ©rÃ© en 5-10 secondes
- âœ… PR prÃªte Ã  review
- âœ… Dev notifiÃ©
- âœ… Utilisateur voit message gracieux

---

### 2. ğŸ” Code Quality Guardian (Analyse Pre-Commit)

**ScÃ©nario** : DÃ©veloppeur essaie de commit du code

```python
# .git/hooks/pre-commit (ou via pre-commit framework)

#!/usr/bin/env python3

import sys
from app.ai.modules.code_assistant.core.service import CodeAssistantService
from app.ai.modules.code_assistant.analyzers.code_quality_analyzer import CodeQualityAnalyzer

async def pre_commit_analysis():
    """
    Workflow:
    1. RÃ©cupÃ¨re les fichiers modifiÃ©s
    2. Analyse chaque fichier
    3. DÃ©tecte: bugs, security issues, architecture violations
    4. Bloque le commit si critique
    5. Affiche suggestions si warnings
    """
    
    # 1. Fichiers modifiÃ©s
    changed_files = git.get_staged_files()
    
    if not changed_files:
        print("âœ… Aucun fichier Ã  analyser")
        return 0
    
    print(f"ğŸ” Analyse de {{len(changed_files)}} fichier(s)....")
    
    # 2. Analyse
    code_assistant = CodeAssistantService()
    issues = {
        "critical": [],
        "warnings": [],
        "suggestions": []
    }
    
    for file_path in changed_files:
        # Skip non-Python files
        if not file_path.endswith('.py'):
            continue
        
        # Charge le contexte projet
        project_context = code_assistant.load_project_context(file_path)
        
        # Analyse multi-niveaux
        result = await code_assistant.analyze_file(
            file_path=file_path,
            project_context=project_context,
            checks=[
                "bugs",
                "security",
                "performance",
                "architecture",
                "code_quality"
            ]
        )
        
        # CatÃ©gorise les issues
        issues["critical"].extend(result.critical_issues)
        issues["warnings"].extend(result.warnings)
        issues["suggestions"].extend(result.suggestions)
    
    # 3. Affichage rÃ©sultats
    if issues["critical"]:
        print("\nâŒ COMMIT BLOQUÃ‰ - Issues critiques dÃ©tectÃ©es:\n")
        for issue in issues["critical"]:
            print(f"  âŒ {{issue.file}}:{{issue.line}}")
            print(f"     {{issue.type}}: {{issue.message}}")
            print(f"     ğŸ’¡ Fix suggÃ©rÃ©: {{issue.suggested_fix}}\n")
        
        print("ğŸ‘‰ Corrige ces issues avant de commit")
        return 1  # Bloque le commit
    
    if issues["warnings"]:
        print("\nâš ï¸  Warnings dÃ©tectÃ©s (commit autorisÃ©):\n")
        for warning in issues["warnings"]:
            print(f"  âš ï¸  {{warning.file}}:{{warning.line}}")
            print(f"     {{warning.message}}")
            print(f"     ğŸ’¡ {{warning.suggestion}}\n")
    
    if issues["suggestions"]:
        print("\nğŸ’¡ Suggestions d'amÃ©lioration:\n")
        for suggestion in issues["suggestions"]:
            print(f"  ğŸ’¡ {{suggestion.file}}:{{suggestion.line}}")
            print(f"     {{suggestion.message}}\n")
    
    if not issues["critical"] and not issues["warnings"] and not issues["suggestions"]:
        print("âœ… Code parfait ! Aucune issue dÃ©tectÃ©e")
    
    return 0  # Autorise le commit

if __name__ == "__main__":
    sys.exit(asyncio.run(pre_commit_analysis()))
```

**Exemple de sortie** :

```
ğŸ” Analyse de 3 fichier(s)...

âŒ COMMIT BLOQUÃ‰ - Issues critiques dÃ©tectÃ©es:

  âŒ app/modules/transcription/service.py:45
     SQL Injection: RequÃªte SQL construite avec f-string
     ğŸ’¡ Fix suggÃ©rÃ©: Utilise des paramÃ¨tres bindÃ©s:
        # Avant
        query = f"SELECT * FROM users WHERE id = {{user_id}}"
        # AprÃ¨s
        query = "SELECT * FROM users WHERE id = :user_id"
        result = session.execute(query, {{"user_id": user_id}})

  âŒ app/api/v1/auth.py:123
     Security: Mot de passe stockÃ© sans hash
     ğŸ’¡ Fix suggÃ©rÃ©: Utilise bcrypt ou passlib

ğŸ‘‰ Corrige ces issues avant de commit
```

---

### 3. ğŸ—ï¸ Architecture Validator

**ScÃ©nario** : Valide que le nouveau code respecte l'architecture dÃ©finie

```python
# app/ai/modules/code_assistant/analyzers/architecture_validator.py

from app.ai.modules.code_assistant.core.context_builder import ContextBuilder

class ArchitectureValidator:
    def __init__(self):
        self.context_builder = ContextBuilder()
        self.project_map = self.context_builder.load_project_map()
    
    async def validate_changes(self, file_path: str, new_code: str) -> ValidationResult:
        """
        Valide que le code respecte l'architecture
        
        Checks:
        1. Module independence (pas de dÃ©pendances circulaires)
        2. Layered architecture (API â†’ Service â†’ Repository)
        3. Import rules (core ne dÃ©pend pas de modules)
        4. Naming conventions
        5. File placement (bon dossier selon le type)
        """
        
        violations = []
        
        # 1. Analyse des imports
        imports = self.extract_imports(new_code)
        
        # Trouve le module actuel
        current_module = self.find_module_for_file(file_path)
        
        # VÃ©rifie dÃ©pendances autorisÃ©es
        for imp in imports:
            if not self.is_import_allowed(current_module, imp):
                violations.append({
                    "type": "forbidden_import",
                    "severity": "critical",
                    "message": f"Import non autorisÃ©: {{imp}}",
                    "reason": f"Le module '{{current_module}}' ne peut pas dÃ©pendre de '{{imp}}'",
                    "suggestion": self.suggest_alternative_import(current_module, imp)
                })
        
        # 2. VÃ©rifie dÃ©pendances circulaires
        if self.creates_circular_dependency(current_module, imports):
            violations.append({
                "type": "circular_dependency",
                "severity": "critical",
                "message": "DÃ©pendance circulaire dÃ©tectÃ©e",
                "cycle": self.find_dependency_cycle(current_module, imports)
            })
        
        # 3. VÃ©rifie layered architecture
        layer_violations = self.check_layer_violations(file_path, imports)
        violations.extend(layer_violations)
        
        # 4. VÃ©rifie naming conventions
        naming_violations = self.check_naming_conventions(file_path, new_code)
        violations.extend(naming_violations)
        
        return ValidationResult(
            valid=len(violations) == 0,
            violations=violations
        )
    
    def is_import_allowed(self, current_module: str, import_path: str) -> bool:
        """
        RÃ¨gles d'architecture:
        - app.core ne dÃ©pend de rien (sauf libs externes)
        - app.models ne dÃ©pend que de app.core
        - app.api dÃ©pend de app.services
        - app.services dÃ©pend de app.models + app.core
        - app.ai.modules peuvent dÃ©pendre de app.core + app.models
        - app.ai.modules NE PEUVENT PAS se dÃ©pendre entre eux
        """
        
        rules = {
            "app.core": [],  # Pas de dÃ©pendances internes
            "app.models": ["app.core"],
            "app.api": ["app.services", "app.schemas", "app.core"],
            "app.services": ["app.models", "app.core"],
            "app.ai.modules.*": ["app.core", "app.models"]  # Mais pas d'autres modules
        }
        
        # ImplÃ©mentation de la logique...
        return True  # ou False
```

**Exemple d'utilisation** :

```python
# Dans le pre-commit hook

validator = ArchitectureValidator()

for file in changed_files:
    result = await validator.validate_changes(file, new_code)
    
    if not result.valid:
        print(f"\nâŒ Violations d'architecture dans {{file}}:")
        for violation in result.violations:
            print(f"  â€¢ {{violation['message']}}")
            if 'suggestion' in violation:
                print(f"    ğŸ’¡ {{violation['suggestion']}}")
```

---

### 4. ğŸ”„ Refactoring Assistant (AmÃ©lioration Continue)

**ScÃ©nario** : Analyse quotidienne automatique du codebase

```python
# app/ai/modules/code_assistant/tasks/daily_code_review.py

from celery import Task
from app.tasks.celery_app import celery_app

@celery_app.task(name="daily_code_review")
async def daily_code_review():
    """
    TÃ¢che planifiÃ©e (2h du matin):
    1. Analyse tout le codebase
    2. DÃ©tecte code smells, duplications, complexitÃ© excessive
    3. GÃ©nÃ¨re suggestions de refactoring
    4. CrÃ©e des issues GitHub avec les suggestions
    5. Calcule mÃ©triques de qualitÃ© (tendances)
    """
    
    code_assistant = CodeAssistantService()
    project_map = code_assistant.load_project_map()
    
    report = {
        "date": datetime.utcnow().isoformat(),
        "modules_analyzed": 0,
        "issues_found": [],
        "refactoring_opportunities": [],
        "metrics": {}
    }
    
    # Analyse chaque module
    for module in project_map["modules"]:
        print(f"ğŸ” Analyse du module: {{module['name']}}")
        
        module_analysis = await code_assistant.analyze_module(
            module_path=module["path"],
            files=module["files"],
            dependencies=module["dependencies"]
        )
        
        report["modules_analyzed"] += 1
        
        # Code smells
        if module_analysis.code_smells:
            for smell in module_analysis.code_smells:
                report["issues_found"].append({
                    "module": module["name"],
                    "type": "code_smell",
                    "file": smell.file,
                    "line": smell.line,
                    "smell": smell.type,  # "long_method", "god_class", etc.
                    "severity": smell.severity
                })
        
        # Duplication
        if module_analysis.duplications:
            for dup in module_analysis.duplications:
                report["issues_found"].append({
                    "module": module["name"],
                    "type": "duplication",
                    "files": dup.files,
                    "lines": dup.lines_duplicated,
                    "suggestion": "Extraire en fonction commune"
                })
        
        # ComplexitÃ© excessive
        if module_analysis.complex_functions:
            for func in module_analysis.complex_functions:
                if func.cyclomatic_complexity > 10:
                    report["refactoring_opportunities"].append({
                        "module": module["name"],
                        "type": "high_complexity",
                        "file": func.file,
                        "function": func.name,
                        "complexity": func.cyclomatic_complexity,
                        "suggestion": await code_assistant.suggest_refactoring(func)
                    })
        
        # MÃ©triques
        report["metrics"][module["name"]] = {
            "maintainability_index": module_analysis.maintainability_index,
            "test_coverage": module_analysis.test_coverage,
            "avg_complexity": module_analysis.avg_complexity,
            "code_smells_count": len(module_analysis.code_smells)
        }
    
    # CrÃ©er des issues GitHub pour les refactorings suggÃ©rÃ©s
    for opportunity in report["refactoring_opportunities"]:
        await create_refactoring_issue(opportunity)
    
    # Sauvegarde le rapport
    save_report(report)
    
    # Notifie l'Ã©quipe
    await notify_team(
        title="ğŸ“Š Rapport de qualitÃ© de code quotidien",
        message=format_report_summary(report)
    )
    
    return report

async def create_refactoring_issue(opportunity: dict):
    """CrÃ©e une issue GitHub avec la suggestion"""
    
    issue_body = f"""
## ğŸ”„ OpportunitÃ© de Refactoring

**Module**: {{opportunity['module']}}
**Type**: {{opportunity['type']}}
**Fichier**: {{opportunity['file']}}

### ProblÃ¨me
{opportunity['description']}

### Suggestion
{opportunity['suggestion']['description']}

### Code Avant
```python
{opportunity['suggestion']['before']}
```

### Code AprÃ¨s (suggÃ©rÃ©)
```python
{opportunity['suggestion']['after']}
```

### BÃ©nÃ©fices
- RÃ©duction complexitÃ©: {{opportunity['complexity']}} â†’ {{opportunity['suggestion']['new_complexity']}}
- Meilleure testabilitÃ©
- Plus maintenable

### Effort EstimÃ©
â±ï¸ {{opportunity['suggestion']['estimated_time']}} minutes

---
*GÃ©nÃ©rÃ© automatiquement par AI Code Assistant*
    """
    
    await github_service.create_issue(
        title=f"â™»ï¸ Refactoring: {{opportunity['function']}} ({{opportunity['module']}})",
        body=issue_body,
        labels=["refactoring", "ai-suggested", "low-priority"]
    )
```

**Exemple d'issue GitHub crÃ©Ã©e** :

```markdown
## ğŸ”„ OpportunitÃ© de Refactoring

**Module**: transcription
**Type**: high_complexity
**Fichier**: app/ai/modules/transcription/service.py

### ProblÃ¨me
La fonction `process_transcription` a une complexitÃ© cyclomatique de 15 (seuil: 10).
Elle contient trop de branches if/else et gÃ¨re plusieurs responsabilitÃ©s.

### Suggestion
Extraire la logique de validation, de traitement et de sauvegarde en mÃ©thodes sÃ©parÃ©es.

### Code Avant
```python
async def process_transcription(self, job_id: str):
    job = await self.get_job(job_id)
    if not job:
        raise NotFound()
    if job.status != "pending":
        raise InvalidStatus()
    # ... 50 lignes de code avec 15 branches
```

### Code AprÃ¨s (suggÃ©rÃ©)
```python
async def process_transcription(self, job_id: str):
    job = await self._validate_job(job_id)
    audio_file = await self._extract_audio(job.video_url)
    transcript = await self._transcribe_audio(audio_file)
    await self._save_transcript(job, transcript)

async def _validate_job(self, job_id: str) -> Job:
    # Validation logic
    pass

async def _extract_audio(self, video_url: str) -> AudioFile:
    # Extraction logic
    pass
# ... etc
```

### BÃ©nÃ©fices
- RÃ©duction complexitÃ©: 15 â†’ 4 par fonction
- Meilleure testabilitÃ© (chaque fonction testable sÃ©parÃ©ment)
- Plus maintenable (responsabilitÃ©s sÃ©parÃ©es)

### Effort EstimÃ©
â±ï¸ 30 minutes

---
*GÃ©nÃ©rÃ© automatiquement par AI Code Assistant*
```

---

## ğŸ”Œ IntÃ©gration avec project-map.json

**Le fichier project-map.json est ESSENTIEL pour le Code Assistant !**

### Pourquoi ?

```python
# app/ai/modules/code_assistant/core/context_builder.py

class ContextBuilder:
    """
    Construit le contexte riche pour l'AI depuis project-map.json
    """
    
    def __init__(self):
        with open("project-map.json") as f:
            self.project_map = json.load(f)
    
    def build_context_for_error(self, file_path: str, error: Exception) -> str:
        """
        Construit un contexte dÃ©taillÃ© pour l'AI
        
        Le project-map.json permet de savoir:
        1. Dans quel module se trouve le fichier
        2. Quelles sont ses dÃ©pendances
        3. Quelle est l'architecture globale
        4. Quels autres fichiers sont liÃ©s
        """
        
        # 1. Trouve le module
        module = self.find_module_for_file(file_path)
        
        # 2. Charge les dÃ©pendances
        dependencies = module["dependencies"]
        
        # 3. Charge les fichiers liÃ©s
        related_files = self.find_related_files(file_path, module)
        
        # 4. Construit le prompt pour l'AI
        context = f"""
# Contexte du Projet

## Projet: {{self.project_map['project']['name']}}
Version: {{self.project_map['project']['version']}}

## Module Actuel: {{module['name']}}
Type: {{module['type']}}
Path: {{module['path']}}

## Fichier avec Erreur
Path: {{file_path}}
Exports: {{self.get_file_exports(file_path)}}
Imports: {{self.get_file_imports(file_path)}}

## DÃ©pendances du Module
Internes:
{{self.format_dependencies(dependencies['internal'])}}

Externes:
{{self.format_dependencies(dependencies['external'])}}

## Architecture Globale
{{self.get_architecture_summary()}}

## Fichiers LiÃ©s (contexte)
{{self.format_related_files(related_files)}}

## Erreur
Type: {{type(error).__name__}}
Message: {{str(error)}}
Traceback: {{traceback.format_exc()}}

## RÃ¨gles d'Architecture Ã  Respecter
{{self.get_architecture_rules(module)}}

---

Analyse l'erreur et propose une correction qui:
1. Corrige le bug
2. Respecte l'architecture du projet
3. Ne casse pas les dÃ©pendances existantes
4. Suit les conventions de code du projet
        """
        
        return context
    
    def find_module_for_file(self, file_path: str) -> dict:
        """Trouve le module qui contient ce fichier"""
        for module in self.project_map["modules"]:
            if file_path.startswith(module["path"]):
                return module
        return None
    
    def find_related_files(self, file_path: str, module: dict) -> list:
        """
        Trouve les fichiers liÃ©s (imports/exports)
        Utilise le project-map pour tracer les dÃ©pendances
        """
        related = []
        
        current_file = next(
            (f for f in module["files"] if f["path"] == file_path),
            None
        )
        
        if not current_file:
            return []
        
        # Fichiers qui importent ce fichier
        for file in module["files"]:
            if any(imp in current_file["exports"] for imp in file["imports"]):
                related.append(file)
        
        # Fichiers importÃ©s par ce fichier
        for imp in current_file["imports"]:
            for file in module["files"]:
                if imp in file["exports"]:
                    related.append(file)
        
        return related
```

### Exemple de Contexte GÃ©nÃ©rÃ© pour l'AI

```
# Contexte du Projet

## Projet: SaaS-IA
Version: 1.0.0

## Module Actuel: transcription
Type: ai_module
Path: app/ai/modules/transcription

## Fichier avec Erreur
Path: app/ai/modules/transcription/service.py
Exports: ['TranscriptionService', 'process_video']
Imports: ['assemblyai', 'app.core.cache', 'app.models.transcription']

## DÃ©pendances du Module
Internes:
- app.core.cache (CacheService)
- app.core.database (get_session)
- app.models.transcription (Transcription, TranscriptionJob)

Externes:
- assemblyai==1.2.3 (Transcription API)
- yt-dlp==2024.1.1 (YouTube download)
- language-tool-python==2.8 (Correction orthographe)

## Architecture Globale
Le projet suit une architecture modulaire avec:
- Core layer (infrastructure)
- AI modules layer (services IA indÃ©pendants)
- API layer (REST endpoints)

RÃ¨gle: Les modules IA ne peuvent PAS dÃ©pendre entre eux.
RÃ¨gle: Toute interaction avec la DB passe par les services core.

## Fichiers LiÃ©s (contexte)
1. app/ai/modules/transcription/routes.py (utilise TranscriptionService)
2. app/models/transcription.py (dÃ©finit le modÃ¨le Transcription)
3. app/core/cache.py (utilisÃ© pour caching)

## Erreur
Type: AttributeError
Message: 'NoneType' object has no attribute 'text'
Traceback: [...] 

## RÃ¨gles d'Architecture Ã  Respecter
1. Ne pas importer d'autres modules IA
2. Utiliser CacheService pour tout caching
3. Passer par get_session() pour accÃ¨s DB
4. Lever des exceptions custom (TranscriptionError)
5. Logger toutes les erreurs avec structlog

---

Analyse l'erreur et propose une correction qui:
1. Corrige le bug
2. Respecte l'architecture du projet
3. Ne casse pas les dÃ©pendances existantes
4. Suit les conventions de code du projet
```

**RÃ©sultat** : L'AI a TOUT le contexte nÃ©cessaire pour gÃ©nÃ©rer un fix cohÃ©rent !

---

## ğŸ¤– Providers IA

### 1. OpenAI Provider (GPT-4)

```python
# app/ai/modules/code_assistant/providers/openai_provider.py

from openai import AsyncOpenAI

class OpenAIProvider:
    def __init__(self):
        self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
    
    async def analyze_error(self, context: str) -> AnalysisResult:
        """Utilise GPT-4 pour analyser une erreur"""
        
        response = await self.client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[
                {
                    "role": "system",
                    "content": """
Tu es un expert Python/FastAPI qui analyse des bugs.
                
Tu dois:
1. Comprendre la cause root du bug
2. Proposer un fix minimal et sÃ»r
3. GÃ©nÃ©rer le code corrigÃ© complet
4. Expliquer pourquoi ce fix fonctionne
5. SuggÃ©rer des tests pour valider le fix
                
RÃ©ponds en JSON avec cette structure:
{
    "root_cause": "string",
    "confidence": 0.0-1.0,
    "fix": {
        "description": "string",
        "code": "string",
        "diff": "string"
    },
    "tests": ["string"],
    "explanation": "string"
}
"""
                },
                {
                    "role": "user",
                    "content": context
                }
            ],
            response_format={"type": "json_object"},
            temperature=0.2  # Bas pour avoir des rÃ©sultats dÃ©terministes
        )
        
        result = json.loads(response.choices[0].message.content)
        
        return AnalysisResult(
            root_cause=result["root_cause"],
            confidence=result["confidence"],
            fix=Fix(**result["fix"]),
            tests=result["tests"],
            explanation=result["explanation"]
        )
```

### 2. Claude Provider (Anthropic)

```python
# app/ai/modules/code_assistant/providers/claude_provider.py

from anthropic import AsyncAnthropic

class ClaudeProvider:
    def __init__(self):
        self.client = AsyncAnthropic(api_key=settings.ANTHROPIC_API_KEY)
    
    async def review_code(self, code: str, context: str) -> ReviewResult:
        """Utilise Claude pour code review approfondie"""
        
        response = await self.client.messages.create(
            model="claude-3-opus-20240229",
            max_tokens=4096,
            messages=[{
                "role": "user",
                "content": f"""
Effectue une code review dÃ©taillÃ©e de ce code.

Context:
{{context}}

Code Ã  review:
```python
{{code}}
```

Analyse:
1. Bugs potentiels
2. VulnÃ©rabilitÃ©s sÃ©curitÃ©
3. Performance issues
4. Code smells
5. Violations best practices

Format JSON:
{{
    "bugs": [...],
    "security": [...],
    "performance": [...],
    "code_quality": [...],
    "suggestions": [...]
}}
"""
            }]
        )
        
        result = json.loads(response.content[0].text)
        return ReviewResult(**result)
```

### 3. Local Analyzer (Outils statiques)

```python
# app/ai/modules/code_assistant/providers/local_analyzer.py

import subprocess
from pylint import epylint as lint
from mypy import api as mypy_api

class LocalAnalyzer:
    """
    Utilise outils locaux (gratuits):
    - pylint (qualitÃ© code)
    - mypy (type checking)
    - ruff (linting ultra-rapide)
    - bandit (sÃ©curitÃ©)
    """
    
    def analyze_file(self, file_path: str) -> LocalAnalysisResult:
        """Analyse avec tous les outils locaux"""
        
        results = {
            "pylint": self.run_pylint(file_path),
            "mypy": self.run_mypy(file_path),
            "ruff": self.run_ruff(file_path),
            "bandit": self.run_bandit(file_path)
        }
        
        return LocalAnalysisResult(**results)
    
    def run_pylint(self, file_path: str) -> dict:
        """Execute pylint"""
        (stdout, stderr) = lint.py_run(f"{file_path} --output-format=json", return_std=True)
        return json.loads(stdout.getvalue())
    
def run_mypy(self, file_path: str) -> dict:
        """Execute mypy"""
        result = mypy_api.run([file_path, "--json"])
        return json.loads(result[0]) if result[0] else {}
    
def run_ruff(self, file_path: str) -> dict:
        """Execute ruff"""
        result = subprocess.run(
            ["ruff", "check", file_path, "--output-format=json"],
            capture_output=True,
            text=True
        )
        return json.loads(result.stdout) if result.stdout else {}
    
def run_bandit(self, file_path: str) -> dict:
        """Execute bandit (sÃ©curitÃ©)"""
        result = subprocess.run(
            ["bandit", "-f", "json", file_path],
            capture_output=True,
            text=True
        )
        return json.loads(result.stdout) if result.stdout else {}
```

**StratÃ©gie combinÃ©e** :
1. **Local Analyzer** d'abord (gratuit, rapide) pour dÃ©tection basique
2. **Claude** pour code review si changements importants
3. **GPT-4** pour gÃ©nÃ©ration de fixes complexes

---

## ğŸ’° Estimation des CoÃ»ts

### CoÃ»ts par OpÃ©ration

| OpÃ©ration | Provider | Tokens | CoÃ»t Unitaire | FrÃ©quence/Jour |
|-----------|----------|--------|---------------|----------------|
| **Auto-Fix Error** | GPT-4 Turbo | ~2000 | $0.02 | 5-10 |
| **Pre-Commit Analysis** | Local + Claude | ~1000 | $0.005 | 20-50 |
| **Daily Code Review** | Claude Opus | ~10000 | $0.15 | 1 |
| **Architecture Validation** | Local | 0 | $0 | 50-100 |

### CoÃ»t Mensuel EstimÃ©

**DÃ©veloppement actif** (1 dev):
- Erreurs production: 10/jour Ã— $0.02 = $0.20/jour = **$6/mois**
- Commits: 30/jour Ã— $0.005 = $0.15/jour = **$4.50/mois**
- Code review: 1/jour Ã— $0.15 = $0.15/jour = **$4.50/mois**

**Total: ~$15/mois** (trÃ¨s abordable pour l'usage interne)

**Ã‰quipe 5 devs**: ~$50-75/mois

---

## ğŸ“Š MÃ©triques & Suivi

### Dashboard de MÃ©triques

```python
# app/ai/modules/code_assistant/metrics/dashboard.py

class CodeAssistantMetrics:
    """MÃ©triques du Code Assistant"""
    
    async def get_dashboard_data(self) -> dict:
        return {
            "auto_fixes": {
                "total": await self.count_auto_fixes(),
                "success_rate": await self.calculate_success_rate(),
                "avg_confidence": await self.get_avg_confidence(),
                "time_saved_hours": await self.estimate_time_saved()
            },
            "code_quality": {
                "bugs_prevented": await self.count_bugs_prevented(),
                "security_issues_caught": await self.count_security_catches(),
                "architecture_violations_blocked": await self.count_violations_blocked()
            },
            "costs": {
                "monthly_api_cost": await self.calculate_monthly_cost(),
                "cost_per_fix": await self.calculate_cost_per_fix(),
                "roi": await self.calculate_roi()  # Temps gagnÃ© vs coÃ»t
            }
        }
```

### Exemple de Dashboard

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           AI Code Assistant - Dashboard                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                            â•‘
â•‘  ğŸ“Š Auto-Fixes (Ce Mois)                                  â•‘
â•‘  â”œâ”€ Total: 47                                             â•‘
â•‘  â”œâ”€ Success Rate: 87% (41 acceptÃ©s, 6 rejetÃ©s)           â•‘
â•‘  â”œâ”€ Avg Confidence: 0.89                                  â•‘
â•‘  â””â”€ Time Saved: ~23.5 heures                              â•‘
â•‘                                                            â•‘
â•‘  ğŸ›¡ï¸  Code Quality                                          â•‘
â•‘  â”œâ”€ Bugs Prevented: 12                                    â•‘
â•‘  â”œâ”€ Security Issues Caught: 3                             â•‘
â•‘  â””â”€ Architecture Violations Blocked: 8                    â•‘
â•‘                                                            â•‘
â•‘  ğŸ’° Costs                                                  â•‘
â•‘  â”œâ”€ Monthly API Cost: $14.23                              â•‘
â•‘  â”œâ”€ Cost per Fix: $0.30                                   â•‘
â•‘  â””â”€ ROI: 98x (23.5h Ã— $50/h = $1,175 saved)              â•‘
â•‘                                                            â•‘
â•‘  ğŸ” Top Issues Fixed                                       â•‘
â•‘  1. AttributeError (12 occurrences)                       â•‘
â•‘  2. SQL Injection risks (3 occurrences)                   â•‘
â•‘  3. Missing error handling (8 occurrences)                â•‘
â•‘                                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸš€ Roadmap d'ImplÃ©mentation

### Semaine 1: Infrastructure de Base
- [ ] Setup module code_assistant
- [ ] ImplÃ©mentation ContextBuilder (avec project-map.json)
- [ ] ImplÃ©mentation OpenAI Provider
- [ ] ImplÃ©mentation LocalAnalyzer
- [ ] Tests unitaires

### Semaine 2: Auto-Healing System
- [ ] Exception handler global
- [ ] GÃ©nÃ©ration de fixes
- [ ] IntÃ©gration GitHub (crÃ©ation PR)
- [ ] Tests d'intÃ©gration
- [ ] Documentation

### Semaine 3: Pre-Commit Analysis
- [ ] Git hooks setup
- [ ] Analyseurs (bugs, security, architecture)
- [ ] Architecture Validator
- [ ] Tests end-to-end

### Semaine 4: Daily Code Review
- [ ] TÃ¢che Celery planifiÃ©e
- [ ] DÃ©tection code smells
- [ ] GÃ©nÃ©ration issues GitHub
- [ ] Dashboard mÃ©triques

### Semaine 5: Raffinement & Monitoring
- [ ] AmÃ©lioration prompts IA
- [ ] Tuning confidence thresholds
- [ ] Dashboard Grafana
- [ ] Documentation utilisateur

---

## ğŸ”’ SÃ©curitÃ© & Bonnes Pratiques

### 1. Validation des Fixes GÃ©nÃ©rÃ©s

```python
# Ne JAMAIS appliquer un fix automatiquement en production

# âœ… BON
if analysis.confidence > 0.90 and not is_production():
    await create_fix_pr(fix)  # CrÃ©e PR pour review humaine

# âŒ MAUVAIS
if analysis.confidence > 0.80:
    await apply_fix_directly(fix)  # Dangereux !
```

### 2. Audit Trail

```python
# Logger TOUS les fixes gÃ©nÃ©rÃ©s
await audit_log.log({
    "event": "auto_fix_generated",
    "error": error_context,
    "analysis": analysis,
    "fix": fix,
    "confidence": analysis.confidence,
    "applied": False,
    "pr_url": pr_url
})
```

### 3. Rate Limiting

```python
# Limiter les appels API
if await rate_limiter.is_exceeded("code_assistant", limit=100, window="1h"):
    # Fallback sur LocalAnalyzer
    return await local_analyzer.analyze(file_path)
```

---

## ğŸ“ Configuration

```yaml
# app/ai/modules/code_assistant/manifest.yaml

name: code_assistant
version: 1.0.0
description: AI-powered code analysis and auto-fixing

providers:
  openai:
    enabled: true
    model: gpt-4-turbo-preview
    max_tokens: 4096
    temperature: 0.2  
  
  claude:
    enabled: true
    model: claude-3-opus-20240229
    max_tokens: 4096
  
  local:
    enabled: true
    tools:
      - pylint
      - mypy
      - ruff
      - bandit

features:
  auto_healing:
    enabled: true
    confidence_threshold: 0.85
    create_pr: true
    auto_merge: false  # Toujours false !
  
  pre_commit_analysis:
    enabled: true
    block_on_critical: true
    tools: [local, claude]
  
  architecture_validation:
    enabled: true
    strict_mode: true
    rules_file: architecture-rules.yaml
  
  daily_review:
    enabled: true
    schedule: "0 2 * * *"  # 2h du matin
    create_issues: true

costs:
  monthly_budget: 50  # USD
  alert_threshold: 0.8  # 80% du budget

dependencies:
  internal:
    - app.core.database
    - app.core.cache
    - app.core.github_service
  external:
    - openai==1.12.0
    - anthropic==0.18.1
    - pylint==3.0.3
    - mypy==1.8.0
    - ruff==0.2.1
    - bandit==1.7.6
```

---

## âœ… Checklist de Mise en Production

- [ ] project-map.json gÃ©nÃ©rÃ© et Ã  jour
- [ ] Providers IA configurÃ©s (API keys)
- [ ] Git hooks installÃ©s
- [ ] Tests unitaires >80% coverage
- [ ] Dashboard mÃ©triques opÃ©rationnel
- [ ] Documentation complÃ¨te
- [ ] Budget monitoring configurÃ©
- [ ] Audit trail activÃ©
- [ ] Rate limiting configurÃ©
- [ ] Alertes configurÃ©es (Slack/Email)

---

## ğŸ“ Support

Pour questions ou issues:
- ğŸ“§ Email: dev@saas-ia.com
- ğŸ’¬ GitHub Issues: /issues
- ğŸ“š Documentation: /docs/code-assistant

---

**CrÃ©Ã© le**: 2025-11-13 19:26:19
**Version**: 1.0.0  
**Auteur**: @benziane  
**Statut**: ğŸš€ PrÃªt Ã  implÃ©menter